{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchvision.transforms import Resize, ToTensor\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "# from models.resnet import ResNet18VisualEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load images function\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((100, 100)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.png'):\n",
    "            img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "            img = transform(img)\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "images = load_images('./maze_maps2')\n",
    "\n",
    "# Load trajectories data\n",
    "data = np.load('trajectories_1.npy', allow_pickle=True)  # Load trajectories data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet18VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18VisualEncoder, self).__init__()\n",
    "        # self.resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.resnet18 = resnet18(weights=None)  # Initialize without pre-trained weights\n",
    "        self.resnet18 = nn.Sequential(*list(self.resnet18.children())[:-2])  # Remove the last two layers\n",
    "        # self.softmax_pooling = nn.AdaptiveAvgPool2d((1, 1))  # Add a softmax pooling layer\n",
    "        self.softmax_pooling = nn.Softmax(dim=1)  # Add softmax layer with dim=1\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.resnet18(images)\n",
    "        pooled_features = self.softmax_pooling(features)\n",
    "        pooled_features = torch.flatten(pooled_features, 1)  # Flatten the features\n",
    "        return pooled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Resnet_Visual_Encoder(images):\n",
    "    encoder = ResNet18VisualEncoder()\n",
    "    latent_embeddings = encoder(images)\n",
    "    return latent_embeddings\n",
    "latent_embeddings = ResNet18VisualEncoder()(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Pathl function\n",
    "def Pathl(data):\n",
    "    trajectories = [d['trajectory'] for d in data]\n",
    "    lengths = [len(traj) for traj in trajectories]\n",
    "    return lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate lengths\n",
    "lengths = Pathl(data)\n",
    "path_lengths = lengths    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the add_gaussian_noise function\n",
    "def add_gaussian_noise(image, noise_level, std):\n",
    "    noise = torch.randn(image.shape) * std\n",
    "    noisy_image = image + noise\n",
    "    noisy_image = nn.functional.normalize(noisy_image, dim=0, p=2.0)  # Normalize across channel dimension\n",
    "    return noisy_image, noise_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the create_cosine_noise_schedule function\n",
    "def create_cosine_noise_schedule(num_timesteps, std_min, std_max):\n",
    "    steps = list(range(num_timesteps))\n",
    "    noise_levels = [std_min + 0.5 * (std_max - std_min) * (1 + math.cos(math.pi * t / num_timesteps)) for t in steps]\n",
    "    return noise_levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the generate_noisy_trajectories function\n",
    "def generate_noisy_trajectories(images, data, std_min, std_max, num_timesteps):\n",
    "    latent_dim = latent_embeddings.shape[1]\n",
    "    noisy_trajectories = []\n",
    "\n",
    "    # Calculate the noise schedule\n",
    "    noise_schedule = create_cosine_noise_schedule(num_timesteps, std_min, std_max)\n",
    "\n",
    "    # Generate a noisy trajectory for each image\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        trajectory = data[i]['trajectory']\n",
    "        length = len(trajectory)\n",
    "\n",
    "        # Generate noisy trajectory points\n",
    "        noisy_trajectory = []\n",
    "        for j in range(length):\n",
    "            t = j / length\n",
    "            t = int(t)\n",
    "            std = noise_schedule[t]\n",
    "            noisy_image, noise_level = add_gaussian_noise(image, t, std)\n",
    "            noisy_trajectory.append(noisy_image)\n",
    "\n",
    "        # Stack the noisy trajectory points\n",
    "        noisy_trajectory = torch.stack(noisy_trajectory)\n",
    "\n",
    "        # Add the noisy trajectory to the list\n",
    "        noisy_trajectories.append(noisy_trajectory)\n",
    "\n",
    "    return noisy_trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate noisy trajectories\n",
    "noisy_trajectories = generate_noisy_trajectories(images, data, std_min=0.1, std_max=0.5, num_timesteps=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the noisy_maze_1 folder if it doesn't exist\n",
    "if not os.path.exists('noisy_maze_2'):\n",
    "    os.makedirs('noisy_maze_2')\n",
    "\n",
    "# Save the noisy images to the noisy_maze_1 folder\n",
    "for i, noisy_trajectory in enumerate(noisy_trajectories):\n",
    "    for j, noisy_image in enumerate(noisy_trajectory):\n",
    "        noisy_image = to_pil_image(noisy_image)\n",
    "        noisy_image.save(f'noisy_maze_2/{i}_{j}.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
