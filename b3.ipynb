{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the .npy file to inspect its contents\n",
    "trajectories_data = np.load('trajectories_3.npy', allow_pickle=True)\n",
    "print(type(trajectories_data))\n",
    "print(trajectories_data.shape)\n",
    "print(trajectories_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Define the Resnet_Visual_Encoder function\n",
    "class ResNet18VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18VisualEncoder, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=False)\n",
    "        # Replace the global max pooling with softmax pooling\n",
    "        self.resnet18.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.softmax_pooling = nn.Softmax(dim=1)\n",
    "        # Remove the final fully connected layer\n",
    "        self.resnet18 = nn.Sequential(*list(self.resnet18.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        x = self.softmax_pooling(x)\n",
    "        return x\n",
    "\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    transform = transforms.Compose([transforms.Resize((100, 100)), transforms.ToTensor()])\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.png'):\n",
    "            img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "            img = transform(img)\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "def Resnet_Visual_Encoder():\n",
    "    encoder = ResNet18VisualEncoder()\n",
    "    images = load_images('./maze_maps3')\n",
    "    latent_embeddings = encoder(images)\n",
    "    return latent_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Define the Pathl function\n",
    "def Pathl(data):\n",
    "    trajectories = data['trajectories']\n",
    "    lengths = [len(traj) for traj in trajectories]\n",
    "    return lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Define the adding_Gaussian_noise function\n",
    "def cosine_noise_scheduler(T, beta_start=0.0001, beta_end=0.02):\n",
    "    return np.cos((np.linspace(0, T, T) + 0.008) / (1.008) * np.pi * 0.5) ** 2 * (beta_end - beta_start) + beta_start\n",
    "\n",
    "def adding_Gaussian_noise(lengths, trajectories):\n",
    "    noisy_trajectories = []\n",
    "    T = 1000  # Number of diffusion steps\n",
    "    beta_schedule = cosine_noise_scheduler(T)\n",
    "    for i, length in enumerate(lengths):\n",
    "        trajectory = trajectories[i]\n",
    "        noise = np.random.normal(0, 1, (length, 2))\n",
    "        noisy_trajectory = trajectory + noise * beta_schedule[:length, None]\n",
    "        noisy_trajectories.append(noisy_trajectory)\n",
    "    return noisy_trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the noise_prediction_network function\n",
    "class NoisePredictionNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(NoisePredictionNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train_noise_prediction_network(latent_embeddings, start_goal, noisy_trajectories, actual_noises, epochs=2, lr=0.1):\n",
    "    model = NoisePredictionNetwork(input_dim=latent_embeddings.shape[1] + 4, output_dim=2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(noisy_trajectories)):\n",
    "            # Flatten latent_embeddings to match the dimensions of start_goal\n",
    "            latent_embedding = latent_embeddings[i].view(latent_embeddings[i].size(0), -1).squeeze()\n",
    "            inputs = torch.cat((latent_embedding, start_goal[i].flatten()), dim=-1)\n",
    "            predictions = model(inputs)\n",
    "            loss = criterion(predictions, actual_noises[i])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the DiPPeR model\n",
    "class DiPPeR(nn.Module):\n",
    "    def __init__(self, noise_prediction_network):\n",
    "        super(DiPPeR, self).__init__()\n",
    "        self.noise_prediction_network = noise_prediction_network\n",
    "\n",
    "    def forward(self, O, noisy_trajectory, path_length):\n",
    "        denoised_trajectory = noisy_trajectory\n",
    "        for t in reversed(range(path_length)):\n",
    "            noise_pred = self.noise_prediction_network(O)\n",
    "            denoised_trajectory = denoised_trajectory - noise_pred\n",
    "        return denoised_trajectory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data and create model\n",
    "latent_embeddings = Resnet_Visual_Encoder()\n",
    "trajectories_data = np.load('trajectories_3.npy', allow_pickle=True)\n",
    "\n",
    "print(\"Type of loaded data: \", type(trajectories_data))\n",
    "print(\"Shape of loaded data: \", trajectories_data.shape)\n",
    "\n",
    "# Assuming the data is a list of dictionaries\n",
    "trajectories = [data['trajectory'] for data in trajectories_data]\n",
    "start_goal = [torch.tensor([data['start'], data['goal']]) for data in trajectories_data]\n",
    "lengths = Pathl({'trajectories': trajectories})\n",
    "\n",
    "# Adding Gaussian noise to the trajectories\n",
    "noisy_trajectories = adding_Gaussian_noise(lengths, trajectories)\n",
    "\n",
    "# Ensure both lists have the same length\n",
    "min_length = min(len(noisy_trajectories), len(trajectories))\n",
    "noisy_trajectories = noisy_trajectories[:min_length]\n",
    "trajectories = trajectories[:min_length]\n",
    "\n",
    "# Convert lists to tensors and pad/truncate to ensure same dimensions\n",
    "padded_noisy_trajectories = pad_sequence([torch.tensor(traj) for traj in noisy_trajectories], batch_first=True)\n",
    "padded_trajectories = pad_sequence([torch.tensor(traj) for traj in trajectories], batch_first=True)\n",
    "\n",
    "# Convert lists to tensors\n",
    "noisy_trajectories_tensor = padded_noisy_trajectories\n",
    "trajectories_tensor = padded_trajectories\n",
    "\n",
    "# Perform element-wise subtraction to get actual_noises\n",
    "actual_noises = noisy_trajectories_tensor - trajectories_tensor\n",
    "\n",
    "# Convert start_goal to a tensor\n",
    "start_goal = torch.stack(start_goal)\n",
    "\n",
    "print(\"Actual noises: \", actual_noises)\n",
    "print(\"Start and Goal: \", start_goal)\n",
    "\n",
    "# Train the noise prediction network\n",
    "noise_prediction_model = train_noise_prediction_network(latent_embeddings, start_goal, noisy_trajectories_tensor, actual_noises)\n",
    "\n",
    "# Create and use the DiPPeR model\n",
    "dipper_model = DiPPeR(noise_prediction_model)\n",
    "final_trajectories = [dipper_model(latent_embeddings[i], noisy_trajectories_tensor[i], lengths[i]) for i in range(len(noisy_trajectories_tensor))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thakk\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectories_data shape: (10,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'latent_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Update the input dimension when creating the model\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m model \u001b[38;5;241m=\u001b[39m NoisePredictionNetwork(input_dim\u001b[38;5;241m=\u001b[39mlatent_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m start_goal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m start_goal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_noise_prediction_network\u001b[39m(latent_embeddings, start_goal, noisy_trajectories, actual_noises, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m):\n\u001b[0;32m     91\u001b[0m     model \u001b[38;5;241m=\u001b[39m NoisePredictionNetwork(input_dim\u001b[38;5;241m=\u001b[39mlatent_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'latent_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from PIL import Image\n",
    "\n",
    "# Load the .npy file to inspect its contents\n",
    "trajectories_data = np.load('trajectories_3.npy', allow_pickle=True)\n",
    "print(\"Loaded trajectories_data shape:\", trajectories_data.shape)\n",
    "\n",
    "# Step 1: Define the ResNet18VisualEncoder class\n",
    "class ResNet18VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18VisualEncoder, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=False)\n",
    "        # Replace the global max pooling with softmax pooling\n",
    "        self.resnet18.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.softmax_pooling = nn.Softmax(dim=1)\n",
    "        # Remove the final fully connected layer\n",
    "        self.resnet18 = nn.Sequential(*list(self.resnet18.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        x = self.softmax_pooling(x)\n",
    "        return x\n",
    "\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    transform = transforms.Compose([transforms.Resize((100, 100)), transforms.ToTensor()])\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.png'):\n",
    "            img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "            img = transform(img)\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "def Resnet_Visual_Encoder():\n",
    "    encoder = ResNet18VisualEncoder()\n",
    "    images = load_images('./maze_maps3')\n",
    "    latent_embeddings = encoder(images)\n",
    "    return latent_embeddings\n",
    "\n",
    "# Step 2: Define the Pathl function\n",
    "def Pathl(data):\n",
    "    trajectories = data['trajectories']\n",
    "    lengths = [len(traj) for traj in trajectories]\n",
    "    return lengths\n",
    "\n",
    "# Step 3: Define the adding_Gaussian_noise function\n",
    "def cosine_noise_scheduler(T, beta_start=0.0001, beta_end=0.02):\n",
    "    return np.cos((np.linspace(0, T, T) + 0.008) / (1.008) * np.pi * 0.5) ** 2 * (beta_end - beta_start) + beta_start\n",
    "\n",
    "def adding_Gaussian_noise(lengths, trajectories):\n",
    "    noisy_trajectories = []\n",
    "    T = 1000  # Number of diffusion steps\n",
    "    beta_schedule = cosine_noise_scheduler(T)\n",
    "    for i, length in enumerate(lengths):\n",
    "        trajectory = trajectories[i]\n",
    "        noise = np.random.normal(0, 1, (length, 2))\n",
    "        noisy_trajectory = trajectory + noise * beta_schedule[:length, None]\n",
    "        noisy_trajectories.append(noisy_trajectory)\n",
    "    return noisy_trajectories\n",
    "\n",
    "# Step 4: Define the noise_prediction_network function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NoisePredictionNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(NoisePredictionNetwork, self).__init__()\n",
    "        # Adjust the input dimensions to match the concatenated input\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_noise_prediction_network(latent_embeddings, start_goal, noisy_trajectories, actual_noises, epochs=2, lr=0.01):\n",
    "    model = NoisePredictionNetwork(input_dim=latent_embeddings.shape[1] + 4, output_dim=2)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(noisy_trajectories)):\n",
    "            # Flatten latent_embeddings to match the dimensions of start_goal\n",
    "            latent_embedding = latent_embeddings[i].view(-1)  # Flatten to 1D tensor\n",
    "            start_goal_flat = start_goal[i].view(-1)  # Flatten start_goal to 1D tensor\n",
    "            inputs = torch.cat((latent_embedding, start_goal_flat), dim=0).float()  # Convert to float\n",
    "\n",
    "            # Make inputs compatible with the model\n",
    "            inputs = inputs.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            # Ensure predictions and actual_noises have the same shape for loss computation\n",
    "            actual_noise = actual_noises[i].view(predictions.shape).float()  # Reshape to match predictions\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(noisy_trajectories)}], Predictions shape: {predictions.shape}, Actual noise shape: {actual_noise.shape}\")\n",
    "\n",
    "            loss = criterion(predictions, actual_noise)  # Convert to float if needed\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  # No need to retain the graph\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Assuming your data is already defined and properly shaped\n",
    "latent_embeddings = torch.rand(5, 512, 1, 1)  # Example latent embeddings\n",
    "start_goal = torch.rand(5, 2, 2)  # Example start and goal positions\n",
    "noisy_trajectories_tensor = torch.rand(5, 191, 2)  # Example noisy trajectories\n",
    "actual_noises = torch.rand(5, 191, 2)  # Example actual noises\n",
    "\n",
    "# Ensure the number of elements matches across tensors\n",
    "min_length = min(len(latent_embeddings), len(start_goal), len(noisy_trajectories_tensor), len(actual_noises))\n",
    "latent_embeddings = latent_embeddings[:min_length]\n",
    "start_goal = start_goal[:min_length]\n",
    "noisy_trajectories_tensor = noisy_trajectories_tensor[:min_length]\n",
    "actual_noises = actual_noises[:min_length]\n",
    "\n",
    "print(f\"latent_embeddings shape: {latent_embeddings.shape}\")\n",
    "print(f\"start_goal shape: {start_goal.shape}\")\n",
    "print(f\"noisy_trajectories_tensor shape: {noisy_trajectories_tensor.shape}\")\n",
    "print(f\"actual_noises shape: {actual_noises.shape}\")\n",
    "\n",
    "assert latent_embeddings.shape[0] == start_goal.shape[0] == noisy_trajectories_tensor.shape[0] == actual_noises.shape[0], \"Batch size mismatch!\"\n",
    "\n",
    "# Train the noise prediction network\n",
    "noise_prediction_model = train_noise_prediction_network(latent_embeddings, start_goal, noisy_trajectories_tensor, actual_noises)\n",
    "\n",
    "\n",
    "# Step 5: Define the DiPPeR model\n",
    "class DiPPeR(nn.Module):\n",
    "    def __init__(self, noise_prediction_network):\n",
    "        super(DiPPeR, self).__init__()\n",
    "        self.noise_prediction_network = noise_prediction_network\n",
    "\n",
    "    def forward(self, O, noisy_trajectory, path_length):\n",
    "        denoised_trajectory = noisy_trajectory\n",
    "        for t in reversed(range(path_length)):\n",
    "            noise_pred = self.noise_prediction_network(O)\n",
    "            denoised_trajectory = denoised_trajectory - noise_pred\n",
    "        return denoised_trajectory\n",
    "\n",
    "# Load data and create model\n",
    "latent_embeddings = Resnet_Visual_Encoder().float()\n",
    "trajectories_data = np.load('trajectories_3.npy', allow_pickle=True)\n",
    "\n",
    "print(\"Type of loaded data: \", type(trajectories_data))\n",
    "print(\"Shape of loaded data: \", trajectories_data.shape)\n",
    "\n",
    "# Assuming the data is a list of dictionaries\n",
    "trajectories = [data['trajectory'] for data in trajectories_data]\n",
    "start_goal = [torch.tensor([data['start'], data['goal']]).float() for data in trajectories_data]\n",
    "lengths = Pathl({'trajectories': trajectories})\n",
    "\n",
    "# Adding Gaussian noise to the trajectories\n",
    "noisy_trajectories = adding_Gaussian_noise(lengths, trajectories)\n",
    "\n",
    "# Ensure both lists have the same length\n",
    "min_length = min(len(noisy_trajectories), len(trajectories), latent_embeddings.shape[0])\n",
    "noisy_trajectories = noisy_trajectories[:min_length]\n",
    "trajectories = trajectories[:min_length]\n",
    "\n",
    "# Convert lists to tensors and pad/truncate to ensure same dimensions\n",
    "padded_noisy_trajectories = pad_sequence([torch.tensor(traj) for traj in noisy_trajectories], batch_first=True).float()\n",
    "padded_trajectories = pad_sequence([torch.tensor(traj) for traj in trajectories], batch_first=True).float()\n",
    "\n",
    "# Convert lists to tensors\n",
    "noisy_trajectories_tensor = padded_noisy_trajectories[:min_length]\n",
    "trajectories_tensor = padded_trajectories[:min_length]\n",
    "\n",
    "# Perform element-wise subtraction to get actual_noises\n",
    "actual_noises = noisy_trajectories_tensor - trajectories_tensor\n",
    "\n",
    "# Convert start_goal to a tensor and ensure correct batch size\n",
    "start_goal = torch.stack(start_goal)[:min_length]\n",
    "\n",
    "# Check shapes before training\n",
    "print(f\"latent_embeddings shape: {latent_embeddings[:min_length].shape}\")\n",
    "print(f\"start_goal shape: {start_goal.shape}\")\n",
    "print(f\"noisy_trajectories_tensor shape: {noisy_trajectories_tensor.shape}\")\n",
    "print(f\"actual_noises shape: {actual_noises.shape}\")\n",
    "\n",
    "# Ensure the number of elements matches across tensors\n",
    "assert latent_embeddings[:min_length].shape[0] == start_goal.shape[0] == noisy_trajectories_tensor.shape[0] == actual_noises.shape[0], \"Batch size mismatch!\"\n",
    "\n",
    "# Train the noise prediction network\n",
    "noise_prediction_model = train_noise_prediction_network(latent_embeddings[:min_length], start_goal, noisy_trajectories_tensor, actual_noises)\n",
    "\n",
    "# Create and use the DiPPeR model\n",
    "dipper_model = DiPPeR(noise_prediction_model)\n",
    "final_trajectories = [dipper_model(latent_embeddings[i], noisy_trajectories_tensor[i], lengths[i]) for i in range(len(noisy_trajectories_tensor))]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
