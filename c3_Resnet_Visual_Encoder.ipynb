{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchvision.transforms import Resize, ToTensor\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "# from models.resnet import ResNet18VisualEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load images function\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((100, 100)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.png'):\n",
    "            img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "            img = transform(img)\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data image data\n",
    "images = load_images('./maze_maps2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load trajectories data with allow_pickle=True\n",
    "# data = np.load('trajectories_2.npy', allow_pickle=True)  # Load trajectories data\n",
    "\n",
    "\n",
    "# # trajectories variable is used for forward_diffusion_process and add_noise\n",
    "# trajectories = data\n",
    "\n",
    "\n",
    "# # Display the shape and a few sample data points of the loaded trajectories\n",
    "# trajectories.shape, trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialSoftmax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialSoftmax, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, channels, height, width]\n",
    "        # Apply softmax along the spatial dimensions (height and width)\n",
    "        softmax = torch.nn.functional.softmax(x.view(x.size(0), x.size(1), -1), dim=2)\n",
    "        return softmax.view(*x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet18VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18VisualEncoder, self).__init__()\n",
    "        \n",
    "        # self.resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.resnet18 = resnet18(weights=None)  # Initialize without pre-trained weights\n",
    "        \n",
    "        self.resnet18 = nn.Sequential(*list(self.resnet18.children())[:-2])  # Remove the last two layers\n",
    "        \n",
    "        # self.softmax_pooling = nn.AdaptiveAvgPool2d((1, 1))  # Add a softmax pooling layer\n",
    "        # self.softmax_pooling = nn.Softmax()  # Add softmax layer with dim=1\n",
    "        # self.softmax_pooling = nn.Softmax(dim=1)  # Add softmax layer with dim=1\n",
    "\n",
    "        self.softmax_pooling = SpatialSoftmax()  # Add spatial softmax pooling\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.resnet18(images)\n",
    "        # pooled_features = self.softmax_pooling(features)\n",
    "        pooled_features = self.softmax_pooling(features)\n",
    "        # pooled_features = torch.flatten(pooled_features, 1)  # Flatten the features\n",
    "        return pooled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18VisualEncoder(\n",
       "  (resnet18): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (softmax_pooling): SpatialSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and use the model\n",
    "encoder = ResNet18VisualEncoder()\n",
    "encoder.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    latent_embeddings = encoder(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the latent embeddings\n",
    "print(latent_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_feature_maps_subset(feature_maps, num_maps=64):\n",
    "    batch_size, channels, height, width = feature_maps.shape\n",
    "    for i in range(batch_size):\n",
    "        fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
    "        for j in range(num_maps):\n",
    "            ax = axes[j // 8, j % 8]\n",
    "            ax.imshow(feature_maps[i, j].detach().cpu().numpy(), cmap='viridis')\n",
    "            ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Visualize the first sample in the batch\n",
    "visualize_feature_maps_subset(latent_embeddings[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv4 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = F.relu(self.deconv3(x))\n",
    "        x = torch.sigmoid(self.deconv4(x))  # Use sigmoid to get pixel values between 0 and 1\n",
    "        return x\n",
    "\n",
    "# Instantiate and use the decoder\n",
    "decoder = Decoder()\n",
    "decoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructed_images = decoder(latent_embeddings)\n",
    "\n",
    "# Visualize the reconstructed images\n",
    "def visualize_reconstructed_images(images):\n",
    "    images = images.permute(0, 2, 3, 1).detach().cpu().numpy()  # Change shape to [batch_size, height, width, channels]\n",
    "    for img in images:\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "visualize_reconstructed_images(reconstructed_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
