{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Load images function\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    transform = transforms.Compose([transforms.Resize((100, 100)), transforms.ToTensor()])\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.png'):\n",
    "            img = Image.open(os.path.join(folder, filename)).convert('RGB')\n",
    "            img = transform(img)\n",
    "            images.append(img)\n",
    "    return torch.stack(images)\n",
    "\n",
    "# Define the Resnet_Visual_Encoder function\n",
    "class ResNet18VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18VisualEncoder, self).__init__()\n",
    "        self.resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.resnet18 = nn.Sequential(*list(self.resnet18.children())[:-2])\n",
    "\n",
    "    def forward(self, images):\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.resnet18(images)\n",
    "        return embeddings\n",
    "\n",
    "def Resnet_Visual_Encoder(images):\n",
    "    encoder = ResNet18VisualEncoder()\n",
    "    latent_embeddings = encoder(images)\n",
    "    return latent_embeddings\n",
    "\n",
    "# Define the Pathl function\n",
    "def Pathl(data):\n",
    "    trajectories = [d['trajectory'] for d in data]\n",
    "    lengths = [len(traj) for traj in trajectories]\n",
    "    return lengths\n",
    "\n",
    "# Define the adding_Gaussian_noise function\n",
    "# Cosine noise scheduler\n",
    "def cosine_noise_scheduler(T, beta_start=0.0001, beta_end=0.02):\n",
    "    return np.cos((np.linspace(0, T, T) + 0.008) / (1.008) * np.pi * 0.5) ** 2 * (beta_end - beta_start) + beta_start\n",
    "\n",
    "# Adding Gaussian noise function\n",
    "def adding_Gaussian_noise(lengths, trajectories):\n",
    "    noisy_trajectories = []\n",
    "    T = 1000  # Number of diffusion steps\n",
    "    beta_schedule = cosine_noise_scheduler(T)\n",
    "    for i, length in enumerate(lengths):\n",
    "        trajectory = trajectories[i]\n",
    "        noise = np.random.normal(0, 1, (length, 2))\n",
    "        noisy_trajectory = np.array(trajectory) + noise * beta_schedule[:length, None]\n",
    "        noisy_trajectories.append(noisy_trajectory)\n",
    "    return noisy_trajectories\n",
    "\n",
    "# Define the noise_prediction_network function\n",
    "# Noise prediction network class\n",
    "class NoisePredictionNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(NoisePredictionNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# FiLM layer class\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FiLM, self).__init__()\n",
    "        self.gamma = nn.Linear(in_channels, out_channels)\n",
    "        self.beta = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        gamma = self.gamma(cond).unsqueeze(-1)\n",
    "        beta = self.beta(cond).unsqueeze(-1)\n",
    "        return gamma * x + beta\n",
    "\n",
    "# Temporal CNN with FiLM class\n",
    "class TemporalCNNFiLM(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(TemporalCNNFiLM, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, 64, kernel_size=3, padding=1)\n",
    "        self.film1 = FiLM(latent_dim, 64)\n",
    "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)\n",
    "        self.film2 = FiLM(latent_dim, 32)\n",
    "        self.conv3 = nn.Conv1d(32, 2, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(self.film1(x, cond))\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(self.film2(x, cond))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# Train noise prediction network function\n",
    "def train_noise_prediction_network(latent_embeddings, start_goals, noisy_trajectories, actual_noises, epochs=10, lr=0.001):\n",
    "    latent_dim = latent_embeddings.shape[1] * latent_embeddings.shape[2] * latent_embeddings.shape[3]\n",
    "    model = TemporalCNNFiLM(input_dim=2, latent_dim=latent_dim + 4)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(noisy_trajectories)):\n",
    "            latent_embedding = latent_embeddings[i].view(-1).float()  # Flatten to 1D tensor and convert to float32\n",
    "            start_goal_flat = start_goals[i].view(-1).float()  # Flatten start_goal to 1D tensor and convert to float32\n",
    "            cond = torch.cat((latent_embedding, start_goal_flat), dim=0).float()  # Combine latents and start_goal\n",
    "            noisy_traj = noisy_trajectories[i].permute(1, 0).unsqueeze(0).float()  # [1, 2, T] and convert to float32\n",
    "            actual_noise = actual_noises[i].permute(1, 0).unsqueeze(0).float()  # [1, 2, T] and convert to float32\n",
    "\n",
    "            # Debug print shapes\n",
    "            print(f\"noisy_traj shape: {noisy_traj.shape}\")\n",
    "            print(f\"cond shape: {cond.unsqueeze(0).shape}\")\n",
    "\n",
    "            predictions = model(noisy_traj, cond.unsqueeze(0))\n",
    "            loss = criterion(predictions, actual_noise)  # Compute loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# DiPPeR model class using Temporal CNN with FiLM\n",
    "class DiPPeR(nn.Module):\n",
    "    def __init__(self, noise_prediction_network):\n",
    "        super(DiPPeR, self).__init__()\n",
    "        self.noise_prediction_network = noise_prediction_network\n",
    "\n",
    "    def forward(self, O, noisy_trajectory, path_length, start_goal):\n",
    "        denoised_trajectory = noisy_trajectory\n",
    "        latent_embedding = O.view(-1).float()  # Flatten latent embedding and convert to float32\n",
    "        start_goal_flat = start_goal.view(-1).float()  # Flatten start_goal and convert to float32\n",
    "        cond = torch.cat((latent_embedding, start_goal_flat), dim=0).float()  # Combine latents and start_goal\n",
    "\n",
    "        for t in reversed(range(path_length)):\n",
    "            traj_point = denoised_trajectory[t].view(-1).float()  # Flatten trajectory point and convert to float32\n",
    "            traj_point = traj_point.unsqueeze(0).unsqueeze(0)  # [1, 1, 2]\n",
    "            noise_pred = self.noise_prediction_network(traj_point.permute(0, 2, 1), cond.unsqueeze(0))\n",
    "            denoised_trajectory[t] = denoised_trajectory[t] - noise_pred.squeeze(0).permute(1, 0)\n",
    "\n",
    "        return denoised_trajectory\n",
    "\n",
    "# Load data\n",
    "images = load_images('./maze_maps5')\n",
    "latent_embeddings = Resnet_Visual_Encoder(images)\n",
    "\n",
    "# Load trajectories data\n",
    "data = np.load('trajectories_5.npy', allow_pickle=True)\n",
    "\n",
    "start_goals = []\n",
    "trajectories_list = []\n",
    "for d in data:\n",
    "    start = torch.tensor(d['start'])\n",
    "    goal = torch.tensor(d['goal'])\n",
    "    start_goal = torch.cat((start, goal))  # Concatenate start and goal tensors\n",
    "    start_goals.append(start_goal)\n",
    "    trajectories_list.append(torch.tensor(d['trajectory']))\n",
    "\n",
    "# Calculate lengths and add Gaussian noise\n",
    "lengths = Pathl(data)\n",
    "noisy_trajectories = adding_Gaussian_noise(lengths, trajectories_list)\n",
    "\n",
    "# Ensure all tensors have the same number of elements\n",
    "if len(latent_embeddings) != len(start_goals):\n",
    "    print(f\"Mismatch in the number of images ({len(latent_embeddings)}) and trajectories ({len(start_goals)}). Adjusting...\")\n",
    "\n",
    "    # Adjust latent embeddings to match the number of start_goals\n",
    "    latent_embeddings = latent_embeddings[:len(start_goals)]\n",
    "\n",
    "assert len(latent_embeddings) == len(start_goals) == len(noisy_trajectories), \"Mismatch in number of elements\"\n",
    "\n",
    "# Convert data to tensors\n",
    "noisy_trajectories_tensor = pad_sequence([torch.tensor(traj) for traj in noisy_trajectories], batch_first=True).float()\n",
    "actual_noises = pad_sequence([torch.tensor(traj) - torch.tensor(trajectories_list[i]) for i, traj in enumerate(noisy_trajectories)], batch_first=True).float()\n",
    "\n",
    "# Train the noise prediction network\n",
    "noise_prediction_model = train_noise_prediction_network(latent_embeddings, start_goals, noisy_trajectories_tensor, actual_noises)\n",
    "\n",
    "# Create and use the DiPPeR model\n",
    "dipper_model = DiPPeR(noise_prediction_model)\n",
    "final_trajectories = [dipper_model(latent_embeddings[i], noisy_trajectories_tensor[i], lengths[i], start_goals[i]) for i in range(len(noisy_trajectories_tensor))]\n",
    "\n",
    "# Plot images with trajectories\n",
    "def plot_images_with_trajectories(images, trajectories, output_folder='output_images_5'):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    transform = transforms.ToPILImage()\n",
    "\n",
    "    for i, (image, trajectory) in enumerate(zip(images, trajectories)):\n",
    "        img = transform(image)\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "\n",
    "        trajectory = trajectory.detach().cpu().numpy()\n",
    "        plt.plot(trajectory[:, 0], trajectory[:, 1], marker='o', color='r', linestyle='-')\n",
    "\n",
    "        plt.title(f'Image with Denoised Trajectory {i}')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(output_folder, f'image_with_trajectory_{i}.png'))\n",
    "        plt.close()\n",
    "\n",
    "plot_images_with_trajectories(images, final_trajectories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
